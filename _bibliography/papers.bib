%% journal and magazine articles

@article{DBLP:journals/ai/HernandezYBZSKS23,
  author       = {Carlos Hern{\'{a}}ndez and
                  William Yeoh and
                  Jorge A. Baier and
                  Han Zhang and
                  Luis Suazo and
                  Sven Koenig and
                  Oren Salzman},
  title        = {Simple and Efficient Bi-Objective Search Algorithms via Fast Dominance Checks},
  journal      = {Artificial Intelligence},
  volume       = {314},
  pages        = {103807},
  year         = {2023},
  abbr       = {AIJ},  
  abstract = "Many interesting search problems can be formulated as bi-objective search problems, that is, search problems where two kinds of costs have to be minimized, for example, travel distance and time for transportation problems. Instead of looking for a single optimal path, we compute a Pareto-optimal frontier in bi-objective search, which is a set of paths in which no two paths dominate each other. Bi-objective search algorithms perform dominance checks each time a new path is discovered. Thus, the efficiency of these checks is key to performance. In this article, we propose algorithms for two kinds of bi-objective search problems. First, we consider the problem of computing the Pareto-optimal frontier of the paths that connect a given start state with a given goal state. We propose Bi-Objective A* (BOA*), a heuristic search algorithm based on A*, for this problem. Second, we consider the problem of computing one Pareto-optimal frontier for each state s of the search graph, which contains the paths that connect a given start state with s. We propose Bi-Objective Dijkstra (BOD), which is based on BOA*, for this problem. A common feature of BOA* and BOD is that all dominance checks are performed in constant time, unlike the dominance checks of previous algorithms. We show in our experimental evaluation that both BOA* and BOD are substantially faster than state-of-the-art bi-objective search algorithms.",
  pdf={ai-HernandezYBZSKS23.pdf},  
  bibtex_show={true},    
  selected={true},  
}

@article{DBLP:journals/jair/RachmutZ022,
  author       = {Ben Rachmut and
                  Roie Zivan and
                  William Yeoh},
  title        = {Communication-Aware Local Search for Distributed Constraint Optimization},
  journal      = {Journal of Artificial Intelligence Research},
  volume       = {75},
  pages        = {637--675},
  year         = {2022},
  abbr       = {JAIR},    
  abstract = "Most studies investigating models and algorithms for distributed constraint optimization problems (DCOPs) assume that messages arrive instantaneously and are never lost. Specifically, distributed local search DCOP algorithms, have been designed as synchronous algorithms (i.e., they perform in synchronous iterations in which each agent exchanges messages with all its neighbors), despite running in asynchronous environments. This is true also for an anytime mechanism that reports the best solution explored during the run of synchronous distributed local search algorithms. Thus, when the assumption of perfect communication is relaxed, the properties that were established for the state-of-the-art local search algorithms and the anytime mechanism may not necessarily apply.
  
In this work, we address this limitation by: (1) Proposing a Communication-Aware DCOP model (CA-DCOP) that can represent scenarios with different communication disturbances; (2) Investigating the performance of existing local search DCOP algorithms, specifically Distributed Stochastic Algorithm (DSA) and Maximum Gain Messages (MGM), in the presence of message latency and message loss; (3) Proposing a latency-aware monotonic distributed local search DCOP algorithm; and (4) Proposing an asynchronous anytime framework for reporting the best solution explored by non-monotonic asynchronous local search DCOP algorithms. Our empirical results demonstrate that imperfect communication has a positive effect on distributed local search algorithms due to increased exploration. Furthermore, the asynchronous anytime framework we proposed allows one to benefit from algorithms with inherent explorative heuristics.",
  pdf={jair-RachmutZ022.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/jair/HoangFHYYZ22,
  author       = {Khoi D. Hoang and
                  Ferdinando Fioretto and
                  Ping Hou and
                  William Yeoh and
                  Makoto Yokoo and
                  Roie Zivan},
  title        = {Proactive Dynamic Distributed Constraint Optimization Problems},
  journal      = {Journal of Artificial Intelligence Research},
  volume       = {74},
  pages        = {179--225},
  year         = {2022},
  abbr       = {JAIR},      
  abstract = "The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool for modeling multi-agent coordination problems. To solve DCOPs in a dynamic environment, Dynamic DCOPs (D-DCOPs) have been proposed to model the inherent dynamism present in many coordination problems. D-DCOPs solve a sequence of static problems by reacting to changes in the environment as the agents observe them. Such reactive approaches ignore knowledge about future changes of the problem. To overcome this limitation, we introduce Proactive Dynamic DCOPs (PD-DCOPs), a novel formalism to model D-DCOPs in the presence of exogenous uncertainty. In contrast to reactive approaches, PD-DCOPs are able to explicitly model possible changes of the problem and take such information into account when solving the dynamically changing problem in a proactive manner. The additional expressivity of this formalism allows it to model a wider variety of distributed optimization problems. Our work presents both theoretical and practical contributions that advance current dynamic DCOP models: (i) We introduce Proactive Dynamic DCOPs (PD-DCOPs), which explicitly model how the DCOP will change over time; (ii) We develop exact and heuristic algorithms to solve PD-DCOPs in a proactive manner; (iii) We provide theoretical results about the complexity of this new class of DCOPs; and (iv) We empirically evaluate both proactive and reactive algorithms to determine the trade-offs between the two classes. The final contribution is important as our results are the first that identify the characteristics of the problems that the two classes of algorithms excel in.",
  pdf={jair-HoangFHYYZ22.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/jair/VasileiouYSKCM22,
  author       = {Stylianos Loukas Vasileiou and
                  William Yeoh and
                  Tran Cao Son and
                  Ashwin Kumar and
                  Michael Cashmore and
                  Daniele Magazzeni},
  title        = {A Logic-Based Explanation Generation Framework for Classical and Hybrid
                  Planning Problems},
  journal      = {Journal of Artificial Intelligence Research},
  volume       = {73},
  pages        = {1473--1534},
  year         = {2022},
  abbr       = {JAIR},      
  abstract = "In human-aware planning systems, a planning agent might need to explain its plan to a human user when that plan appears to be non-feasible or sub-optimal. A popular approach, called model reconciliation, has been proposed as a way to bring the model of the human user closer to the agent?s model. To do so, the agent provides an explanation that can be used to update the model of human such that the agent?s plan is feasible or optimal to the human user. Existing approaches to solve this problem have been based on automated planning methods and have been limited to classical planning problems only.

In this paper, we approach the model reconciliation problem from a different perspective, that of knowledge representation and reasoning, and demonstrate that our approach can be applied not only to classical planning problems but also hybrid systems planning problems with durative actions and events/processes. In particular, we propose a logicbased framework for explanation generation, where given a knowledge base KBa (of an agent) and a knowledge base KBh (of a human user), each encoding their knowledge of a planning problem, and that KBa entails a query q (e.g., that a proposed plan of the agent is valid), the goal is to identify an explanation  ? KBa such that when it is used to update KBh, then the updated KBh also entails q. More specifically, we make the following contributions in this paper: (1) We formally define the notion of logic-based explanations in the context of model reconciliation problems; (2) We introduce a number of cost functions that can be used to reflect preferences between explanations; (3) We present algorithms to compute explanations for both classical planning and hybrid systems planning problems; and (4) We empirically evaluate their performance on such problems. Our empirical results demonstrate that, on classical planning problems, our approach is faster than the state of the art when the explanations are long or when the size of the knowledge base is small (e.g., the plans to be explained are short). They also demonstrate that our approach is efficient for hybrid systems planning problems.

Finally, we evaluate the real-world efficacy of explanations generated by our algorithms through a controlled human user study, where we develop a proof-of-concept visualization system and use it as a medium for explanation communication.",
  pdf={jair-VasileiouYSKCM22.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/jair/NguyenYLZ19,
  author       = {Duc Thien Nguyen and
                  William Yeoh and
                  Hoong Chuin Lau and
                  Roie Zivan},
  title        = {Distributed Gibbs: {A} Linear-Space Sampling-Based {DCOP} Algorithm},
  journal      = {Journal of Artificial Intelligence Research},
  volume       = {64},
  pages        = {705--748},
  year         = {2019},
  abbr       = {JAIR},      
  abstract = "Researchers have used distributed constraint optimization problems (DCOPs) to model various multi-agent coordination and resource allocation problems. Very recently, Ottens et al. proposed a promising new approach to solve DCOPs that is based on confidence bounds via their Distributed UCT (DUCT) sampling-based algorithm. Unfortunately, its memory requirement per agent is exponential in the number of agents in the problem, which prohibits it from scaling up to large problems. Thus, in this article, we introduce two new sampling-based DCOP algorithms called Sequential Distributed Gibbs (SD-Gibbs) and Parallel Distributed Gibbs (PD-Gibbs). Both algorithms have memory requirements per agent that is linear in the number of agents in the problem. Our empirical results show that our algorithms can find solutions that are better than DUCT, run faster than DUCT, and solve some large problems that DUCT failed to solve due to memory limitations.",
  pdf={jair-NguyenYLZ19.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/jair/FiorettoPY18,
  author       = {Ferdinando Fioretto and
                  Enrico Pontelli and
                  William Yeoh},
  title        = {Distributed Constraint Optimization Problems and Applications: {A}
                  Survey},
  journal      = {Journal of Artificial Intelligence Research},
  volume       = {61},
  pages        = {623--698},
  year         = {2018},
  abbr       = {JAIR},      
  abstract = "The field of multi-agent system (MAS) is an active area of research within artificial intelligence, with an increasingly important impact in industrial and other real-world applications. In a MAS, autonomous agents interact to pursue personal interests and/or to achieve common objectives. Distributed Constraint Optimization Problems (DCOPs) have emerged as a prominent agent model to govern the agents? autonomous behavior, where both algorithms and communication models are driven by the structure of the specific problem. During the last decade, several extensions to the DCOP model have been proposed to enable support of MAS in complex, real-time, and uncertain environments.

This survey provides an overview of the DCOP model, offering a classification of its multiple extensions and addressing both resolution methods and applications that find a natural mapping within each class of DCOPs. The proposed classification suggests several future perspectives for DCOP extensions and identifies challenges in the design of efficient resolution algorithms, possibly through the adaptation of strategies from different areas.",
  pdf={jair-FiorettoPY18.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/aimatters/FiorettoY18,
  author       = {Ferdinando Fioretto and
                  William Yeoh},
  title        = {{AI} Buzzwords Explained: Distributed Constraint Optimization Problems},
  journal      = {{AI} Matters},
  volume       = {3},
  number       = {4},
  pages        = {8--13},
  year         = {2018},
  abbr       = {AI Matt.},      
  pdf={aimatters-FiorettoY18.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/tist/VarakanthamKLY18,
  author       = {Pradeep Varakantham and
                  Akshat Kumar and
                  Hoong Chuin Lau and
                  William Yeoh},
  title        = {Risk-Sensitive Stochastic Orienteering Problems for Trip Optimization
                  in Urban Environments},
  journal      = {{ACM} Transaction of Intelligent System Technologies},
  volume       = {9},
  number       = {3},
  pages        = {24:1--24:25},
  year         = {2018},
  abbr       = {TIST},      
  abstract = "Orienteering Problems (OPs) are used to model many routing and trip planning problems. OPs are a variant of the well-known traveling salesman problem where the goal is to compute the highest reward path that includes a subset of vertices and has an overall travel time less than a specified deadline. However, the applicability of OPs is limited due to the assumption of deterministic and static travel times. To that end, Campbell et al. extended OPs to Stochastic OPs (SOPs) to represent uncertain travel times [Campbell et al. 2011]. In this paper, we make the following key contributions: (1) We extend SOPs to Dynamic SOPs (DSOPs), which allow for time-dependent travel times; (2) we introduce a new objective criterion for SOPs and DSOPs to represent a percentile measure of risk; (3) we provide non-linear optimization formulations along with their linear equivalents for solving the risk-sensitive SOPs and DSOPs; (4) we provide a local search mechanism for solving the risk-sensitive SOPs and DSOPs; and (5) we provide results on existing benchmark problems and a real-world theme park trip planning problem.",
  pdf={tist-VarakanthamKLY18.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/constraints/FiorettoPYD18,
  author       = {Ferdinando Fioretto and
                  Enrico Pontelli and
                  William Yeoh and
                  Rina Dechter},
  title        = {Accelerating Exact and Approximate Inference for (Distributed) Discrete
                  Optimization with GPUs},
  journal      = {Cons},
  volume       = {23},
  number       = {1},
  pages        = {1--43},
  year         = {2018},
  abbr       = {Const.},      
  abstract = "Discrete optimization is a central problem in artificial intelligence. The optimization of the aggregated cost of a network of cost functions arises in a variety of problems including Weighted Constraint Programs (WCSPs), Distributed Constraint Optimization (DCOP), as well as optimization in stochastic variants such as the tasks of finding the most probable explanation (MPE) in belief networks. Inference-based algorithms are powerful techniques for solving discrete optimization problems, which can be used independently or in combination with other techniques. However, their applicability is often limited by their compute intensive nature and their space requirements. 

This paper proposes the design and implementation of a novel inference-based technique, which exploits modern massively parallel architectures, such as those found in Graphical Processing Units (GPUs), to speed up the resolution of exact and approximated inference-based algorithms for discrete optimization. The paper studies the proposed algorithm in both centralized and distributed optimization contexts.

The paper demonstrates that the use of GPUs provides significant advantages in terms of runtime and scalability, achieving up to two orders of magnitude in speedups and showing a considerable reduction in execution time (up to 345 times faster) with respect to a sequential version.",
  pdf={constraints-FiorettoPYD18.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/ijait/VirvouBBTYTNM18a,
  author       = {Atena M. Tabakhi and
                  William Yeoh and
                  Reza Tourani and
                  Francisco Natividad and
                  Satyajayant Misra},
  title        = {Communication-Sensitive Pseudo-Tree Heuristics for {DCOP} Algorithms},
  journal      = {International Journal on Artificial Intelligence Tools},
  volume       = {27},
  number       = {7},
  pages        = {1860008:1--1860008:24},
  year         = {2018},
  abbr       = {IJAIT},      
  abstract = "Distributed Constraint Optimization Problem (DCOP) is a powerful paradigm to model multi-agent systems through enabling multiple agents to coordinate with each other to solve a problem. These agents are often assumed to be cooperative, that is, they communicate with other agents in order to optimize a global objective. However, the communication times between all pairs of agents are assumed to be identical in the evaluation of most DCOP algorithms. This assumption is impractical in almost all real-world applications. In this paper, we study the impact of empirically evaluating a DCOP algorithm under the assumption that communication times between pairs of agents can vary. In addition, we evaluate a DCOP algorithm using ns-2, a discrete-event simulator that is widely used in the computer networking community, to simulate the communication times, as opposed to the standard DCOP simulators that are used to evaluate DCOP algorithms in the AI community. Furthermore, we propose heuristics that exploit the non-uniform communication times to speed up DCOP algorithms that operate on pseudo-trees. Our empirical results demonstrate that the proposed heuristics improve the runtime of those algorithms up to 20%. These heuristics are evaluated on different benchmarks such as scale-free graphs, random graphs, and an instance of the smart grid, Customer-Driven Microgrid (CDMG) application.",
  pdf={ijait-VirvouBBTYTNM18a.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/tplp/LeSPY17,
  author       = {Tiep Le and
                  Tran Cao Son and
                  Enrico Pontelli and
                  William Yeoh},
  title        = {Solving Distributed Constraint Optimization Problems Using Logic Programming},
  journal      = {Theory and Practice of Logic Programming},
  volume       = {17},
  number       = {4},
  pages        = {634--683},
  year         = {2017},
  abbr       = {TPLP},      
  abstract = "This paper explores the use of Answer Set Programming (ASP) in solving Distributed Constraint Optimization Problems (DCOPs). The paper provides the following novel contributions: (1) it shows how one can formulate DCOPs as logic programs; (2) it introduces ASP-DPOP, the first DCOP algorithm that is based on logic programming; (3) it experimentally shows that ASP-DPOP can be up to two orders of magnitude faster than DPOP (its imperative programming counterpart) as well as solve some problems that DPOP fails to solve, due to memory limitations; and (4) it demonstrates the applicability of ASP in a wide array of multi-agent problems currently modeled as DCOPs.",
  pdf={tplp-LeSPY17.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/expert/AzizBCHKMSSXY16,
  author       = {Haris Aziz and
                  Elias Bareinboim and
                  Yejin Choi and
                  Daniel J. Hsu and
                  Shivaram Kalyanakrishnan and
                  Reshef Meir and
                  Suchi Saria and
                  Gerardo I. Simari and
                  Lirong Xia and
                  William Yeoh},
  title        = {AI's 10 to Watch},
  journal      = {{IEEE} Intelligent Systems},
  volume       = {31},
  number       = {1},
  pages        = {56--66},
  year         = {2016},
  abbr       = {Int. Sys.},    
  pdf={expert-AzizBCHKMSSXY16.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/aim/YeohY12,
  author       = {William Yeoh and
                  Makoto Yokoo},
  title        = {Distributed Problem Solving},
  journal      = {{AI} Magazine},
  volume       = {33},
  number       = {3},
  pages        = {53--65},
  year         = {2012},
  abbr       = {AI Mag.},      
  abstract = "Distributed problem solving is a subfield within multiagent systems, where agents are assumed to be part of a team and collaborate with each other to reach a common goal. In this article, we illustrate the motivations for distributed problem solving and provide an overview of two distributed problem-solving models, namely distributed constraint-satisfaction problems (DCSPs) and distributed constraint-optimization problems (DCOPs), and some of their algorithms.",
  pdf={aim-YeohY12.pdf},  
  bibtex_show={true},    
  selected={true},    
}

@article{DBLP:journals/jair/YeohFK10,
  author       = {William Yeoh and
                  Ariel Felner and
                  Sven Koenig},
  title        = {BnB-ADOPT: An Asynchronous Branch-and-Bound {DCOP} Algorithm},
  journal      = {Journal of Artificial Intelligence Research},
  volume       = {38},
  pages        = {85--133},
  year         = {2010},
  abbr       = {JAIR},      
  abstract = "Distributed constraint optimization (DCOP) problems are a popular way of formulating and solving agent-coordination problems. A DCOP problem is a problem where several agents coordinate their values such that the sum of the resulting constraint costs is minimal. It is often desirable to solve DCOP problems with memory-bounded and asynchronous algorithms. We introduce Branch-and-Bound ADOPT (BnB-ADOPT), a memory-bounded asynchronous DCOP search algorithm that uses the message-passing and communication framework of ADOPT (Modi, Shen, Tambe, & Yokoo, 2005), a well known memory-bounded asynchronous DCOP search algorithm, but changes the search strategy of ADOPT from best-first search to depth-first branch-and-bound search. Our experimental results show that BnB-ADOPT finds cost-minimal solutions up to one order of magnitude faster than ADOPT for a variety of large DCOP problems and is as fast as NCBB, a memory-bounded synchronous DCOP search algorithm, for most of these DCOP problems. Additionally, it is often desirable to find bounded-error solutions for DCOP problems within a reasonable amount of time since finding cost-minimal solutions is NP-hard. The existing bounded-error approximation mechanism allows users only to specify an absolute error bound on the solution cost but a relative error bound is often more intuitive. Thus, we present two new bounded-error approximation mechanisms that allow for relative error bounds and implement them on top of BnB-ADOPT.",
  pdf={jair-YeohFK10.pdf},  
  bibtex_show={true},    
  selected={true},
}

%% Conference publications (full papers)


@inproceedings{tabakhi21,
  author    = "Atena M. Tabakhi and William Yeoh and Roie Zivan",  
  title     = "Incomplete Distributed Constraint Optimization Problems: Model, Algorithms, and Heuristics",
  booktitle = "Proceedings of the International Conference on Distributed Artificial Intelligence (DAI)",
  pages     = "64--78",    
  month = "",
  year      = "2021",
  award={Best Paper Award}    
}

@inproceedings{rachmut21,
  author    = "Ben Rachmut and Roie Zivan and William Yeoh",  
  title     = "Latency-Aware Local Search for Distributed Constraint Optimization",
  booktitle = "Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS)",
  pages     = "1019--1027",  
  year      = "2021"
}

@inproceedings{zivan21,
  author    = "Roie Zivan and Omer Perry and Ben Rachmut and William Yeoh",  
  title     = "The Effect of Asynchronous Execution and Message Latency on {Max-sum}",
  booktitle = "Proceedings of the International Conference on Principles and Practice of Constraint Programming (CP)",
  year      = "2021"
}

@inproceedings{wayllace22,
  author    = "Christabel Wayllace and William Yeoh",  
  title     = "Stochastic Goal Recognition Design Problems with Suboptimal Agents",
  booktitle = "Proceedings of the {AAAI} Conference on Artificial Intelligence (AAAI)",
  year      = "2022"
}

@inproceedings{adt13-incentives,
  author    = "Pradeep Varakantham and Na Fu and William Yeoh and Shih-Fen Cheng and Hoong Chuin Lau",
  title     = "Budgeted Personalized Incentive Approaches for Smoothing Congestion in Resource 
  	       Networks",
  booktitle = "Proceedings of the International Conference on Algorithmic Decision Theory (ADT)",
  month = "November",
  year      = "2013"
}

@inproceedings{naps13-cdmg-dcop,
  author    = "Saurabh Gupta and WIlliam Yeoh and Enrico Pontelli and Palak Jain and Satish Ranade",
  title     = "Modeling Microgrid Islanding Problems as {DCOP}s",
  booktitle = "Proceedings of the North American Power Symposium (NAPS)",
  month = "September",
  year      = "2013"
}

@inproceedings{ijcai13-interactiongraph,
  author    = "William Yeoh and Akshat Kumar and Shlomo Zilberstein",
  title     = "Automated Generation of Interaction Graphs for Value-Factored {Dec-POMDP}s",
  booktitle = "Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI)",
  pages     = "411--417",
  month = "August",
  year      = "2013"
}

@inproceedings{aamas13-dgibbs,
  author    = "Duc Thien Nguyen and William Yeoh and Hoong Chuin Lau",
  title     = "Distributed {G}ibbs: A Memory-Bounded Sampling-Based {DCOP} Algorithm",
  booktitle = "Proceedings of the International Joint Conference on Autonomous Agents and 
	       Multiagent Systems (AAMAS)",
  pages     = "167--174",
  month = "May",
  year      = "2013"
}

@inproceedings{iat12-slr,
  author    = "Geoffrey J. Gordon and Pradeep Varakantham and William Yeoh and Hoong Chuin Lau
  	       and Ajay S. Aravamudhan and Shih-Fen Cheng",
  title     = "Lagrangian Relaxation for Large-Scale Multi-Agent Planning",
  booktitle = "Proceedings of the International Conference on Intelligent Agent Technology (IAT)",
  pages     = "494--501",
  month = "December",
  year      = "2012"
}
