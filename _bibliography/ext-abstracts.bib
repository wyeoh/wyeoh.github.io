%% Conference Papers (Short Papers/Extended Abstracts/Technical Communications)

@inproceedings{DBLP:conf/aamas/TabakhiX0Z21,
  author       = {Atena M. Tabakhi and
                  Yuanming Xiao and
                  William Yeoh and
                  Roie Zivan},
  title        = {Branch-and-Bound Heuristics for Incomplete DCOPs (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1677--1679},
  year         = {2021},
  abbr       = {AAMAS},  
  abstract = {The Incomplete Distributed Constraint Optimization Problem (IDCOP) extends the distributed constraint optimization problem, where constraint costs are allowed to be unspecified. A distributed variant of the Synchronous Branch-and-Bound (SyncBB) search algorithm has been proposed to solve I-DCOPs, where unspecified constraint costs are elicited during its execution. In this paper, we propose two heuristics that can be used in conjunction with SyncBB to solve I-DCOPs. Our proposed heuristics speed up the algorithm by pruning those parts of the search space whose solution quality is sub-optimal. Thus, our model and heuristics extend the state of the art in distributed constraint reasoning to better model and solve distributed agent-based applications with user preferences.},
  pdf={aamas-TabakhiX0Z21.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/kr/NguyenSS020,
  author       = {Van Nguyen and
                  Vasileiou Loukas Stylianos and
                  Tran Cao Son and
                  William Yeoh},
  title        = {Explainable Planning Using Answer Set Programming},
  booktitle    = {Proc. of the International Conference on Principles of Knowledge Representation and Reasoning},
  pages        = {662--666},
  year         = {2020},
  abbr       = {KR},  
  abstract = {In human-aware planning problems, the planning agent may need to explain its plan to a human user, especially when the plan appears infeasible or suboptimal for the user. A popular approach to do so is called model reconciliation, where the planning agent tries to reconcile the differences between its model and the model of the user such that its plan is also feasible and optimal to the user. This problem can be viewed as an optimization problem, where the goal is to find a subset-minimal explanation that one can use to modify the model of the user such that the plan of the agent is also feasible and optimal to the user. This paper presents an algorithm for solving such problems using answer set programming.},
  pdf={kr-NguyenSS020.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/XiaoT020,
  author       = {Yuanming Xiao and
                  Atena M. Tabakhi and
                  William Yeoh},
  title        = {Embedding Preference Elicitation Within the Search for {DCOP} Solutions (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {2044--2046},
  year         = {2020},
  abbr       = {AAMAS},  
  abstract = {A key assumption in Distributed Constraint Optimization Problem (DCOP) model is that all constraints are fully specified or known a priori, which may not hold in applications where constraints encode preferences of human users. We extend the model to Incomplete DCOPs (I-DCOPs), where some constraints can be partially specified. User preferences for these partially-specified constraints can be elicited during the execution of I-DCOP algorithms, but they incur some elicitation costs. Additionally, we extend the Synchronous Branch-and-Bound (SyncBB) algorithm to solve I-DCOPs. Our model extends the state of the art in distributed constraint reasoning to better model and solve distributed agent-based applications with user preferences.},
  pdf={aamas-XiaoT020.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/NguyenSS020,
  author       = {Van Nguyen and
                  Tran Cao Son and
                  Vasileiou Loukas Stylianos and
                  William Yeoh},
  title        = {Conditional Updates of Answer Set Programming and Its Application in Explainable Planning (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1954--1956},
  year         = {2020},
  abbr       = {AAMAS},  
  abstract = {In explainable planning, the planning agent needs to explain its plan to a human user, especially when the plan appears infeasible or suboptimal for the user. A popular approach is called model reconciliation, where the agent reconciles the differences between its model and the model of the user such that its plan is also feasible and optimal to the user. This problem can be viewed as a more general problem as follows: Given two knowledge bases $\pi_a$ and $\pi_h$ and a query q such that $\pi_a$ entails q and $\pi_h$ does not entail q, where the notion of entailment is dependent on the logical theories underlying $\pi_a$ and $\pi_h$, how to change $\pi_h$ ? given $\pi_a$ and the support for q in $\pi_a$ ? so that $\pi_h$ does entail q. In this paper, we study this problem under the context of answer set programming. To achieve this goal, we (1) define the notion of a conditional update between two logic programs $\pi_a$ and $\pi_h$ with respect to a query q; (2) define the notion of an explanation for a query q from a program $\pi_a$ to a program $\pi_h$ using conditional updates; (3) develop algorithms for computing explanations; and (4) show how the notion of explanation based on conditional updates can be used in explainable planning.},
  pdf={aamas-NguyenSS020.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aaai/WayllaceHHHM0O20,
  author       = {Christabel Wayllace and
                  Sunwoo Ha and
                  Yuchen Han and
                  Jiaming Hu and
                  Shayan Monadjemi and
                  William Yeoh and
                  Alvitta Ottley},
  title        = {{DRAGON-V:} Detection and Recognition of Airplane Goals with Navigational Visualization (Demonstration Track)},
  booktitle    = {Proc. of the {AAAI} Conference on Artificial Intelligence},
  pages        = {13642--13643},
  publisher    = {{AAAI} Press},
  year         = {2020},
  abbr       = {AAAI},  
  abstract = {We introduce Detection and Recognition of Airplane GOals with Navigational Visualization (DRAGON-V), a visualization system that uses probabilistic goal recognition to infer and display the most probable airport runway that a pilot is approaching. DRAGON-V is especially useful in cases of miscommunication, low visibility, or lack of airport familiarity which may result in a pilot deviating from the assigned taxiing route. The visualization system conveys relevant information, and updates according to the airplane?s current geolocation. DRAGON-V aims to assist air traffic controllers in reducing incidents of runway incursions at airports.},
  pdf={aaai-WayllaceHHHM0O20.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/ijcai/Yeoh18,
  author       = {William Yeoh},
  title        = {Towards Improving the Expressivity and Scalability of Distributed Constraint Optimization Problems},
  booktitle    = {Proc. of the International Joint Conference on Artificial Intelligence},
  pages        = {5734--5738},
  year         = {2018},
  abbr       = {IJCAI},  
  abstract = {Constraints have long been studied in centralized systems and have proven to be practical and efficient for modeling and solving resource allocation and scheduling problems. Slightly more than a decade ago, researchers proposed the distributed constraint optimization problem (DCOP) formulation, which is well suited for modeling distributed multi-agent coordination problems. In this paper, we highlight some of our recent contributions that are aiming towards improved expressivity of the DCOP model as well as improved scalability of the accompanying algorithms.},
  pdf={ijcai-Yeoh18.pdf},  
  bibtex_show={true},    
  selected={false},
  award={Paper accompanying early career spotlight presentation}  
}

@inproceedings{DBLP:conf/aamas/ChowdhuryKS018,
  author       = {Moinul Morshed Porag Chowdhury and
                  Christopher Kiekintveld and
                  Tran Cao Son and
                  William Yeoh},
  title        = {Bidding Strategy for Periodic Double Auctions Using Monte Carlo Tree Search (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1897--1899},
  year         = {2018},
  abbr       = {AAMAS},  
  abstract = {Bidding strategies for Periodic Double Auctions (PDAs) are complicated because they need to predict and plan for future auctions, which may affect the bidding strategy in the current auction. We present a general bidding strategy for PDAs based on forecasting clearing prices and using Monte Carlos Tree Search (MCTS) to plan a bidding strategy across multiple time periods. We developed a controlled simulator by isolating Power Trading Agent Competition?s wholesale market to evaluate bidding strategies in a realistic PDA energy market. We show that our MCTS bidding strategy is cost effective in buying energy compared to other baseline and state-of-the-art strategies and it?s performance improves with increasing number of MCTS simulations.},
  pdf={aamas-ChowdhuryKS018.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/Fioretto0P15,
  author       = {Ferdinando Fioretto and
                  William Yeoh and
                  Enrico Pontelli},
  title        = {Multi-Variable Agents Decomposition for DCOPs to Exploit Multi-Level Parallelism (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1823--1824},
  year         = {2015},
  abbr       = {AAMAS},  
  abstract = {Current DCOP algorithms suffer from a major limiting assumption?each agent can handle only a single variable of the problem?which limits their scalability. This paper proposes a novel Multi-Variable Agent (MVA) DCOP decomposition, which: (i) Exploits co-locality of an agent?s variables, allowing us to adopt efficient centralized techniques; (ii) Enables the use of hierarchical parallel models, such us those based on GPGPUs; and (iii) Empirically reduces the amount of communication required in several classes of DCOP algorithms. Experimental results show that our MVA decomposition outperforms non-decomposed DCOP algorithms, in terms of network load and scalability.},
  pdf={aamas-Fioretto0P15.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/FiorettoCDP015,
  author       = {Ferdinando Fioretto and
                  Federico Campeotto and
                  Agostino Dovier and
                  Enrico Pontelli and
                  William Yeoh},
  title        = {Large Neighborhood Search with Quality Guarantees for Distributed Constraint Optimization Problems (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1835--1836},
  year         = {2015},
  abbr       = {AAMAS},  
  abstract = {This paper proposes Distributed Large Neighborhood Search (DLNS), an incomplete DCOP algorithm that builds on the strengths of centralized LNS. D-LNS: (i) is anytime; (ii) provides guarantees on solution quality (upper and lower bounds); and (iii) can learn online the best neighborhood to explore. Experimental results show that D-LNS outperforms other incomplete DCOP algorithms in random and scale-free network instances.},
  pdf={aamas-FiorettoCDP015.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/LeSP014,
  author       = {Tiep Le and
                  Tran Cao Son and
                  Enrico Pontelli and
                  William Yeoh},
  title        = {{ASP-DPOP:} solving distributed constraint optimization problems with logic programming (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1337--1338},
  year         = {2014},
  abbr       = {AAMAS},  
  abstract = {Researchers have used Distributed Constraint Optimization Problems (DCOPs) to model various multi-agent coordination and resource allocation problems. However, existing DCOP algorithms have focused almost exclusively on imperative programming techniques. This paper explores a new direction, which is to develop algorithms that use declarative programming, specifically logic programming, techniques.},
  pdf={aamas-LeSP014.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/NguyenYLZZ14,
  author       = {Duc Thien Nguyen and
                  William Yeoh and
                  Hoong Chuin Lau and
                  Shlomo Zilberstein and
                  Chongjie Zhang},
  title        = {Decentralized multi-agent reinforcement learning in average-reward dynamic DCOPs (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1341--1342},
  year         = {2014},
  abbr       = {AAMAS},  
  abstract = {Researchers have introduced the Dynamic Distributed Constraint Optimization Problem (Dynamic DCOP) formulation to model dynamically changing multi-agent coordination problems, where a dynamic DCOP is a sequence of (static canonical) DCOPs, each partially different from the DCOP preceding it. Existing work typically assumes that the problem in each time step is decoupled from the problems in other time steps, which might not hold in some applications. In this paper, we introduce a new model, called Markovian Dynamic DCOPs (MD-DCOPs), where a DCOP is a function of the value assignments in the preceding DCOP. We also introduce a distributed reinforcement learning algorithm that balances exploration and exploitation to solve MD-DCOPs in an online manner.},
  pdf={aamas-NguyenYLZZ14.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/FiorettoCF0P14,
  author       = {Ferdinando Fioretto and
                  Federico Campeotto and
                  Luca Da Rin Fioretto and
                  William Yeoh and
                  Enrico Pontelli},
  title        = {{GD-GIBBS:} a GPU-based sampling algorithm for solving distributed constraint optimization problems (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1339--1340},
  year         = {2014},
  abbr       = {AAMAS},  
  abstract = {Multi-agent planning is a well-studied problem with applications in various areas. Due to computational constraints, existing research typically focuses either on unstructured domains with many agents, where we are content with heuristic solutions, or domains with small numbers of agents or special structure, where we can find provably near-optimal solutions. In contrast, here we focus on provably near-optimal solutions in domains with many agents, by exploiting influence limits. To that end, we make two key contributions: (a) an algorithm, based on Lagrangian relaxation and randomized rounding, for solving multi-agent planning problems represented as large mixed-integer programs; (b) a proof of convergence of our algorithm to a near-optimal solution.},
  pdf={aamas-FiorettoCF0P14.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/GordonVYLAC12,
  author       = {Geoffrey J. Gordon and
                  Pradeep Varakantham and
                  William Yeoh and
                  Hoong Chuin Lau and
                  Ajay S. Aravamudhan and
                  Shih{-}Fen Cheng},
  title        = {Lagrangian relaxation for large-scale multi-agent planning (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1227--1228},
  year         = {2012},
  abbr       = {AAMAS},  
  abstract = {Multi-agent planning is a well-studied problem with applications in various areas. Due to computational constraints, existing research typically focuses either on unstructured domains with many agents, where we are content with heuristic solutions, or domains with small numbers of agents or special structure, where we can find provably near-optimal solutions. In contrast, here we focus on provably near-optimal solutions in domains with many agents, by exploiting influence limits. To that end, we make two key contributions: (a) an algorithm, based on Lagrangian relaxation and randomized rounding, for solving multi-agent planning problems represented as large mixed-integer programs; (b) a proof of convergence of our algorithm to a near-optimal solution.},
  pdf={aamas-GordonVYLAC12.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/VarakanthamYVSS12,
  author       = {Pradeep Varakantham and
                  William Yeoh and
                  Prasanna Velagapudi and
                  Katia P. Sycara and
                  Paul Scerri},
  title        = {Prioritized shaping of models for solving {DEC-POMDPs} (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1269--1270},
  year         = {2012},
  abbr       = {AAMAS},  
  abstract = {An interesting class of multi-agent POMDP planning problems can be solved by having agents iteratively solve individual POMDPs, find interactions with other individual plans, shape their transition and reward functions to encourage good interactions and discourage bad ones and then recompute a new plan. D-TREMOR showed that this approach can allow distributed planning for hundreds of agents. However, the quality and speed of the planning process depends on the prioritization scheme used. Lower priority agents shape their models with respect to the models of higher priority agents. In this paper, we introduce a new prioritization scheme that is guaranteed to converge and is empirically better, in terms of solution quality and planning time, than the existing prioritization scheme for some problems.},
  pdf={aamas-VarakanthamYVSS12.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/YeohVSK11,
  author       = {William Yeoh and
                  Pradeep Varakantham and
                  Xiaoxun Sun and
                  Sven Koenig},
  title        = {Incremental {DCOP} search algorithms for solving dynamic {DCOP}s (Extended Abstract)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1069--1070},
  year         = {2011},
  abbr       = {AAMAS},  
  abstract = {Distributed constraint optimization problems (DCOPs) are well-suited for modeling multi-agent coordination problems. However, most research has focused on developing algorithms for solving static DCOPs. In this paper, we model dynamic DCOPs as sequences of (static) DCOPs with changes from one DCOP to the next one in the sequence. We introduce the ReuseBounds procedure, which can be used by any-space ADOPT and any-space BnB-ADOPT to find cost-minimal solutions for all DCOPs in the sequence faster than by solving each DCOP individually. This procedure allows those agents that are guaranteed to remain unaffected by a change to reuse their lower and upper bounds from the previous DCOP when solving the next one in the sequence. Our experimental results show that the speedup gained from this procedure increases with the amount of memory the agents have available.},
  pdf={aamas-YeohVSK11.pdf},  
  bibtex_show={true},    
  selected={false},  
}

@inproceedings{DBLP:conf/aamas/YeohKS08,
  author       = {William Yeoh and
                  Sven Koenig and
                  Xiaoxun Sun},
  title        = {Trading off solution cost for smaller runtime in {DCOP} search algorithms (Short Paper)},
  booktitle    = {Proc. of the International Conference on Autonomous Agents and Multiagent Systems},
  pages        = {1445--1448},
  year         = {2008},
  abbr       = {AAMAS},  
  abstract = {Distributed Constraint Optimization (DCOP) is a key technique for solving multiagent coordination problems. Unfortunately, finding minimal-cost DCOP solutions is NP-hard. We therefore propose two mechanisms that trade off the solution costs of two DCOP search algorithms (ADOPT and BnB-ADOPT) for smaller runtimes, namely the Inadmissible Heuristics Mechanism and the Relative Error Mechanism. The solution costs that result from these mechanisms are bounded by a more meaningful quantity than the solution costs that result from the existing Absolute Error Mechanism since they both result in solution costs that are larger than minimal by at most a user-specified percentage. Furthermore, the Inadmissible Heuristics Mechanism experimentally dominates both the Absolute Error Mechanism and the Relative Error Mechanism for BnB-ADOPT and is generally no worse than them for ADOPT.},
  pdf={aamas-YeohKS08.pdf},  
  bibtex_show={true},    
  selected={false},  
}