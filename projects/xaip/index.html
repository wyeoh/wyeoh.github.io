<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>explainable planning and scheduling | William  Yeoh</title>
    <meta name="author" content="William  Yeoh">
    <meta name="description" content="William Yeoh at Washington University in St. Louis
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">
</head>
<body>
<p>
'

    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://wyeoh.github.io/projects/xaip/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  

  <!-- Body -->
  </p>

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">William </span>Yeoh</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">home</a>
              </li>
              


              <!-- Other pages -->
              <!-- External links -->
              <li class="nav-item">
                <a class="nav-link" href="https://yeoh-lab.wustl.edu" rel="external nofollow noopener" target="_blank">research
                </a>
              </li>                            
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <!-- External links -->
              <li class="nav-item">
                <a class="nav-link" href="https://www.cse.wustl.edu/~wyeoh/William%20Yeoh%20-%20CV.pdf" rel="external nofollow noopener" target="_blank">cv
                </a>
              </li>                            
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>                            
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">contact</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">explainable planning and scheduling</h1>
            <p class="post-description"></p>
          </header>

          <article>
            <p><img style="float: left; margin: 5px 10px 5px 0px; width: 240px; box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);" src="/assets/img/project-xaip.jpg">
In human-aware planning and scheduling systems, when the agent recommends a plan or schedule to a human user, it is often the case that the user might not understand why the recommendation is good, for example, compared to an alternative in the user’s mind. In such a scenario, there is a need for the agent to <em>explain</em> its recommendation to the user, providing them with the necessary information to understand properties of the recommendation (e.g., optimality, feasibility, etc.).</p>

<p>We are approaching this problem from a knowledge representation and reasoning (KR) perspective, where we represent the mental models of both the agent and the human user using logical facts and rules. Within this framework, we adapt and generalize KR notions (e.g., entailment, hitting sets, model counting) to solve this problem.</p>

<h3>sponsors</h3>

<p></p>

<p><img style="float: left; margin: 0px 10px 0px 0px;" src="/assets/img/nsf.png" width="50px">
<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2232055" rel="external nofollow noopener" target="_blank">Collaborative Research: RI: Small: End-to-end Learning of Fair and Explainable Schedules for Court Systems</a>.
National Science Foundation (2023 – 2026).</p>

<p><img style="float: left; margin: 0px 10px 0px 0px;" src="/assets/img/jpmc.jpg" width="50px">
<a href="https://www.jpmorgan.com/technology/artificial-intelligence/research-awards/faculty-research-awards-2022" rel="external nofollow noopener" target="_blank">Improving Client Experience Through Goal Recognition and Explainable Assistance in Adaptive Systems</a>.
J.P. Morgan Chase Bank (2022 – 2023).</p>

<p><img style="float: left; margin: 0px 10px 0px 0px;" src="/assets/img/nsf.png" width="50px">
<a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1812619" rel="external nofollow noopener" target="_blank">RI: Small: Collaborative Research: Preference Elicitation and Device Scheduling for Smart Homes</a>.
National Science Foundation (2018 – 2021).<br></p>
<font size="1"><br></font>

<h3>selected publications</h3>

<p></p>

<div class="publications">
  <ol class="bibliography"></ol>

  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-1 abbr"><abbr class="badge">JAIR</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/jair/VasileiouYSKCM22" class="col-sm-10">
        <!-- Title -->
        <div class="title">A Logic-Based Explanation Generation Framework for Classical and Hybrid Planning Problems</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://thestlucas.com/" rel="external nofollow noopener" target="_blank">Stylianos Loukas Vasileiou</a>, <a href="https://wyeoh.github.io/">William Yeoh</a>, <a href="https://www.cs.nmsu.edu/~tson/" rel="external nofollow noopener" target="_blank">Tran Cao Son</a>, and
          <span class="more-authors" title="click to view 3 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '3 more authors' ? 'Ashwin Kumar, Michael Cashmore, Daniele Magazzeni' : '3 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">3 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>Journal of Artificial Intelligence Research</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Awards -->
          <div class="award">
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/jair-VasileiouYSKCM22.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In human-aware planning systems, a planning agent might need to explain its plan to a human user when that plan appears to be non-feasible or sub-optimal. A popular approach, called model reconciliation, has been proposed as a way to bring the model of the human user closer to the agent?s model. To do so, the agent provides an explanation that can be used to update the model of human such that the agent?s plan is feasible or optimal to the human user. Existing approaches to solve this problem have been based on automated planning methods and have been limited to classical planning problems only.

In this paper, we approach the model reconciliation problem from a different perspective, that of knowledge representation and reasoning, and demonstrate that our approach can be applied not only to classical planning problems but also hybrid systems planning problems with durative actions and events/processes. In particular, we propose a logicbased framework for explanation generation, where given a knowledge base KBa (of an agent) and a knowledge base KBh (of a human user), each encoding their knowledge of a planning problem, and that KBa entails a query q (e.g., that a proposed plan of the agent is valid), the goal is to identify an explanation  ⊆KBa such that when it is used to update KBh, then the updated KBh also entails q. More specifically, we make the following contributions in this paper: (1) We formally define the notion of logic-based explanations in the context of model reconciliation problems; (2) We introduce a number of cost functions that can be used to reflect preferences between explanations; (3) We present algorithms to compute explanations for both classical planning and hybrid systems planning problems; and (4) We empirically evaluate their performance on such problems. Our empirical results demonstrate that, on classical planning problems, our approach is faster than the state of the art when the explanations are long or when the size of the knowledge base is small (e.g., the plans to be explained are short). They also demonstrate that our approach is efficient for hybrid systems planning problems.

Finally, we evaluate the real-world efficacy of explanations generated by our algorithms through a controlled human user study, where we develop a proof-of-concept visualization system and use it as a medium for explanation communication.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/jair/VasileiouYSKCM22</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vasileiou, Stylianos Loukas and Yeoh, William and Son, Tran Cao and Kumar, Ashwin and Cashmore, Michael and Magazzeni, Daniele}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Logic-Based Explanation Generation Framework for Classical and Hybrid Planning Problems}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Artificial Intelligence Research}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{73}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1473--1534}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-1 abbr"><abbr class="badge">ICAPS</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/icaps/KumarVBO022" class="col-sm-10">
        <!-- Title -->
        <div class="title">VizXP: A Visualization Framework for Conveying Explanations to Users
                  in Model Reconciliation Problems</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://sites.wustl.edu/ashwinkumar/" rel="external nofollow noopener" target="_blank">Ashwin Kumar</a>, <a href="https://thestlucas.com/" rel="external nofollow noopener" target="_blank">Stylianos Loukas Vasileiou</a>, Melanie Bancilhon, and
          <span class="more-authors" title="click to view 2 more authors" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '2 more authors' ? 'Alvitta Ottley, William Yeoh' : '2 more authors';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">2 more authors</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In International Conference on Automated Planning and Scheduling</em>, 2022
        </div>
        <div class="periodical">
          
        </div>

          <!-- Awards -->
          <div class="award">
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/icaps-KumarVBO022.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Advancements in explanation generation for automated planning algorithms have moved us a step closer towards realizing the full potential of human-AI collaboration in real-world planning applications. Within this context, a framework called model reconciliation has gained a lot of traction, mostly due to its deep connection with a popular theory in human psychology, known as the theory of mind. Existing literature in this setting, however, has mostly been constrained to algorithmic contributions for generating explanations. To the best of our knowledge, there has been very little work on how to effectively convey such explanations to human users, a critical component in human-AI collaboration systems. In this paper, we set out to explore to what extent visualizations are an effective candidate for conveying explanations in a way that can be easily understood. Particularly, by drawing inspiration from work done in visualization systems for classical planning, we propose a visualization framework for visualizing explanations generated from model reconciliation algorithms. We demonstrate the efficacy of our proposed system in a comprehensive user study, where we compare our framework against a text-based baseline for two types of explanations ? domain-based and problem-based explanations. Results from the user study show that users, on average, understood explanations better when they are conveyed via our visualization system compared to when they are conveyed via a text-based baseline.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/icaps/KumarVBO022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kumar, Ashwin and Vasileiou, Stylianos Loukas and Bancilhon, Melanie and Ottley, Alvitta and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{VizXP: {A} Visualization Framework for Conveying Explanations to Users
                    in Model Reconciliation Problems}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Automated Planning and Scheduling}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{701--709}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-1 abbr"><abbr class="badge">AAAI</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/aaai/VasileiouP021" class="col-sm-10">
        <!-- Title -->
        <div class="title">On Exploiting Hitting Sets for Model Reconciliation</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://thestlucas.com/" rel="external nofollow noopener" target="_blank">Stylianos Loukas Vasileiou</a>, Alessandro Previti, and <a href="https://wyeoh.github.io/">William Yeoh</a>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In AAAI Conference on Artificial Intelligence</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Awards -->
          <div class="award">
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/aaai-VasileiouP021.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In human-aware planning, a planning agent may need to provide an explanation to a human user on why its plan is optimal. A popular approach to do this is called model reconciliation, where the agent tries to reconcile the differences in its model and the human?s model such that the plan is also optimal in the human?s model. In this paper, we present a logic-based framework for model reconciliation that extends beyond the realm of planning. More specifically, given a knowledge base KB1 entailing a formula ? and a second knowledge base KB2 not entailing it, model reconciliation seeks an explanation, in the form of a cardinality-minimal subset of KB1, whose integration into KB2 makes the entailment possible. Our approach, based on ideas originating in the context of analysis of inconsistencies, exploits the existing hitting set duality between minimal correction sets (MCSes) and minimal unsatisfiable sets (MUSes) in order to identify an appropriate explanation. However, differently from those works targeting inconsistent formulas, which assume a single knowledge base, MCSes and MUSes are computed over two distinct knowledge bases. We conclude our paper with an empirical evaluation of the newly introduced approach on planning instances, where we show how it outperforms an existing state-of-the-art solver, and generic non-planning instances from recent SAT competitions, for which no other solver exists..</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/aaai/VasileiouP021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vasileiou, Stylianos Loukas and Previti, Alessandro and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On Exploiting Hitting Sets for Model Reconciliation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{AAAI} Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6514--6521}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-1 abbr"><abbr class="badge">JELIA</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/jelia/SonNV021" class="col-sm-10">
        <!-- Title -->
        <div class="title">Model Reconciliation in Logic Programs</div>
        <!-- Author -->
        <div class="author">
        

        <a href="https://www.cs.nmsu.edu/~tson/" rel="external nofollow noopener" target="_blank">Tran Cao Son</a>, Van Nguyen, <a href="https://thestlucas.com/" rel="external nofollow noopener" target="_blank">Stylianos Loukas Vasileiou</a>, and
          <span class="more-authors" title="click to view 1 more author" onclick="
                var element = $(this);
                element.attr('title', '');
                var more_authors_text = element.text() == '1 more author' ? 'William Yeoh' : '1 more author';
                var cursorPosition = 0;
                var textAdder = setInterval(function(){
                  element.text(more_authors_text.substring(0, cursorPosition + 1));
                  if (++cursorPosition == more_authors_text.length){
                    clearInterval(textAdder);
                  }
              }, '10');
              ">1 more author</span>
</div>

        <!-- Journal/Book title and date -->
        
        
        <div class="periodical">
          <em>In European Conference on Logics in Artificial Intelligence</em>, 2021
        </div>
        <div class="periodical">
          
        </div>

          <!-- Awards -->
          <div class="award">
          </div>

          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/jelia-SonNV021.pdf" target="_blank" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>
          
          <div class="badges">
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Inspired by recent research ε^+ in explainable planning, we investigate the model reconciliation problem between two logic programs \pi_a and \pi_h, which represent the knowledge bases of an agent and a human, respectively. Given \pi_a, \pi_h, and a query q such that \pi_a entails q and \pi_h does not entail q (or \pi_a does not entail q and \pi_h entails q), the model reconciliation problem focuses on the question of how to modify \pi_h, by adding  + ⊆\pi_a to \pi_h and removing  ε^- ⊆\pi_h from \pi_h such that the resulting program \hat\pi_h = (\pi_h   ε^-) ∪ε^+ has an answer set containing q (or has no answer set containing q). The pair (ε^+, ε^-) is referred to as a solution for the model reconciliation problem (\pi_a, \pi_h, q) (or (\pi_a, \pi_h, \lnot q)). We prove that, for a reasonable selected set of rules ε^+ ⊆\pi_a there exists a way to modify \pi_h such that \hat\pi_h is guaranteed to credulously entail q (or skeptically entail \lnot q). Given that there are potentially several solutions, we discuss different characterizations of solutions and algorithms for computing solutions for model reconciliation problems.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/jelia/SonNV021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Son, Tran Cao and Nguyen, Van and Vasileiou, Stylianos Loukas and Yeoh, William}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Model Reconciliation in Logic Programs}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{European Conference on Logics in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{393--406}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>

  <ol class="bibliography"></ol>


</div>


          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2023 William  Yeoh. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  
</body>
</html>
